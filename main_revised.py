# -*- coding: utf-8 -*-
"""Main_revised.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a7ntfVFwo1GuxtHxo6VYAdfaxPrcwJe_
"""

!pip install memory-profiler

import math

def swap_position(A, i, j):
    A[i], A[j] = A[j], A[i]

def block_size_calc(n, ratio=10/26):
    # Calculate the block size using a different formula with math.log
    log_inv = 1 / math.log(n, 2)  # Invers dari logaritma basis 2 dari n
    block_size = 2 ** (log_inv * ratio)  # Mengalikan dengan ratio
    block_size = block_size ** 3  # Mengakar pangkat tiga dari hasilnya
    return int(block_size)

def two_pivot_block_partition(A, left, right, block_size):
    p = A[left]
    q = A[right]
    i, j, k = left + 1, left + 1, left + 1
    num_p, num_q = 0, 0
    block = [0] * block_size

    while k < right:
        t = min(block_size, right - k)
        for c in range(t):
            block[num_q] = c
            num_q += (q >= A[k + c])
        for c in range(num_q):
            swap_position(A, j + c, k + block[c])
        k += t
        for c in range(num_q):
            block[num_p] = c
            num_p += (p > A[j + c])
        for c in range(num_p):
            swap_position(A, i, j + block[c])
            i += 1
        j += num_q
        num_p, num_q = 0, 0

    swap_position(A, left, i - 1)
    swap_position(A, right, j)
    return i - 1, j

def two_pivot_block_quicksort_iterative(A):
    stack = [(0, len(A) - 1)]

    while stack:
        left, right = stack.pop()
        if right <= left:
            continue

        # Ensure the first pivot is less than the second pivot
        if A[left] > A[right]:
            swap_position(A, left, right)

        block_size = block_size_calc(right - left + 1)
        i, j = two_pivot_block_partition(A, left, right, block_size)
        stack.append((left, i - 1))
        stack.append((i, j - 1))
        stack.append((j + 1, right))  # Corrected this line

#taken from GeeksForGeeks
def mergeSort(arr):
    if len(arr) > 1:

         # Finding the mid of the array
        mid = len(arr)//2

        # Dividing the array elements
        L = arr[:mid]

        # Into 2 halves
        R = arr[mid:]

        # Sorting the first half
        mergeSort(L)

        # Sorting the second half
        mergeSort(R)

        i = j = k = 0

        # Copy data to temp arrays L[] and R[]
        while i < len(L) and j < len(R):
            if L[i] <= R[j]:
                arr[k] = L[i]
                i += 1
            else:
                arr[k] = R[j]
                j += 1
            k += 1

        # Checking if any element was left
        while i < len(L):
            arr[k] = L[i]
            i += 1
            k += 1

        while j < len(R):
            arr[k] = R[j]
            j += 1
            k += 1

    return arr

import math
import time
import sys
import random
import os

# Add your two-pivot quicksort code here

def analyze_sorting_performance(dataset_size, variation, output_file):
    data = [i for i in range(2 ** dataset_size)]

    if variation == "random":
        random.shuffle(data)

    # Measure memory usage before sorting
    memory_before = sys.getsizeof(data)  # in bytes

    # Measure execution time
    start_time = time.time()
    two_pivot_block_quicksort_iterative(data)  # Pass the entire data list
    end_time = time.time()
    execution_time = (end_time - start_time) * 1000  # in milliseconds

    # Measure memory usage after sorting
    memory_after = sys.getsizeof(data)  # in bytes

    with open(output_file, 'w') as file:
        file.write(f"Dataset: {2 ** dataset_size} elements, Variation: {variation}\n")
        file.write(f"Execution Time: {execution_time:.2f} ms\n")
        file.write(f"Memory Usage Before Sorting: {memory_before} bytes\n")
        file.write(f"Memory Usage After Sorting: {memory_after} bytes\n")
        file.write("===")

variations = ["sorted", "random", "reversed"]

# Dataset sizes: small (2^9), medium (2^13), large (2^16)
dataset_sizes = [9, 13, 16]

output_folder = "sorting_result"  # Nama folder untuk menyimpan hasil
os.makedirs(output_folder, exist_ok=True)  # Membuat folder jika belum ada

for size in dataset_sizes:
    for variation in variations:
        output_file = os.path.join(output_folder, f"results_{2**size}_{variation}.txt")
        analyze_sorting_performance(size, variation, output_file)

import math
import time
import sys
import random
import os

# Kode two_pivot_block_quicksort dan dataset yang telah Anda berikan


def analyze_sorting_performance(dataset_size, variation, output_file):
    data = [i for i in range(2 ** dataset_size)]

    if variation == "random":
        random.shuffle(data)

    # Measure memory usage before sorting
    memory_before = sys.getsizeof(data)  # in bytes

    # Measure execution time
    start_time = time.time()
    mergeSort(data.copy())
    end_time = time.time()
    execution_time = (end_time - start_time) * 1000  # in milliseconds

    # Measure memory usage after sorting
    memory_after = sys.getsizeof(data)  # in bytes

    with open(output_file, 'w') as file:
        file.write(f"Dataset: {2 ** dataset_size} elements, Variation: {variation}\n")
        file.write(f"Execution Time: {execution_time:.2f} ms\n")
        file.write(f"Memory Usage Before Sorting: {memory_before} bytes\n")
        file.write(f"Memory Usage After Sorting: {memory_after} bytes\n")
        file.write("===")

variations = ["sorted", "random", "reversed"]

# Dataset sizes: small (2^9), medium (2^13), large (2^16)
dataset_sizes = [9, 13, 16]

output_folder = "sorting_result_merge"  # Nama folder untuk menyimpan hasil
os.makedirs(output_folder, exist_ok=True)  # Membuat folder jika belum ada

for size in dataset_sizes:
    for variation in variations:
        output_file = os.path.join(output_folder, f"results_{2**size}_{variation}.txt")
        analyze_sorting_performance(size, variation, output_file)